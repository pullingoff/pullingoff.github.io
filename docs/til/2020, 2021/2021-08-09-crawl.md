---
title: "웹 크롤링 vs. 스크래핑 (feat. nodeJS)"
date: 2021-08-09 08:00
---

크롤링과 스크레핑은 다름.

## axios, cheerio

- axios:  브라우저, Node.js를 위한 Promise API를 활용하는 HTTP 비동기 통신 라이브러리
- cheerio: HTML parser, jqery 와 문법 거의 비슷
console.dir 을 보면 객체도 편하게 다 볼 수 있음
로딩중 이후로 오는 서비스(딜레이로딩 되는 놈)를 획득하려면? 브라우저 컨트롤이 필요. 그럴때 puppeteer를 사용가능.

## puppeteer

1. node.js 를 통해 크롬 브라우저 실행
2. 사용자가 원하는 뷰포트, 네트워크 환경 등 설정 가능
3. 마우스, 키보드, 터치 스크린 등 코드를 통해 사람이 사용하는 것처럼 구현 가능 
4. 타임라인 트레이싱(네트워크에서 시간에 ㄸㅏ라 어떤 요청이 오는지 볼수 있음), 스샷, 확장프로그램 테스트, 자동화 등 가능
5. SPA(Single Page App) 크롤링과 pre-rendered content생성 가능(SSR).
   - SPA란 vue.js나 리액트를 써서 만드는 앱이다. 앱처럼 동작하기 때문에 클라이언트 사이드에서 렌더링하는 경우가 많다. 그러면 검색엔진, 크롤러가 정보를 제대로 못 가져오는 경우가 많다. 그럴때 ㅆ면 굿

- 최대한 가볍게는 퍼피티어 코어랑 해당 크롬의 위치 설정해두면 됨

- 모두 npm을 사용해 Npm i puppeteer 이런식으로 설치.
- nodemon -g로 글로벌에 설치해두면 node index.js 이런식으로 터미널에서 계속 실행해줄 필요없이 nodemon index.js 해노면 그 후로 변경사항 있을 때마다 자동 실행


- node.js에는 자바스크립트 엔진이 있어 브라우저 없어도 터미널에서 node blah.js 이런식으로 입력하면 실행 가능
- 웹 API 중 하나인 Console API! js가 제공하는게 아니라 브라우저 제공 함수.
- parsing HTML -> blocked(그동안 fetching js&executing js) -> 다시 parsing HTML

- HTML을 쭉 파싱하다가 script태그 나오면 '오 이 js를 다운받아야하네'하고 파싱을 잠시 멈추고 필요한 js를 서버에서 다운.